# AnÃ¡lisis de Ciencia de Datos

## ğŸ“„ DescripciÃ³n

Este notebook aborda un reto de anÃ¡lisis de datos que incluye la **exploraciÃ³n**, **limpieza**, **ingenierÃ­a de caracterÃ­sticas**, **modelado** y **evaluaciÃ³n** de un conjunto de datos real. El objetivo es extraer insights accionables y construir un modelo predictivo robusto.

## ğŸ“ Estructura del repositorio

```bash
.
â”œâ”€â”€ data/                                # Datos originales (CSV, JSON, etc.)
â”‚   â””â”€â”€ dataset.csv                      # Dataset principal
â”œâ”€â”€ notebooks/                           # Notebooks organizados por fase
â”‚   â””â”€â”€ Reto-Analisis-CienciaDeDatos.ipynb  # Notebook principal
â”œâ”€â”€ docs/                                # DocumentaciÃ³n
â”‚   â””â”€â”€ screenshots/                     # Capturas de pantalla de outputs clave
â”œâ”€â”€ environment.yml or requirements.txt  # Dependencias del proyecto
â””â”€â”€ README.md                            # Este archivo
```

## ğŸš€ Uso

1. Abre el notebook en Jupyter o Colab:

   ```bash
   jupyter lab notebooks/Reto-Analisis-CienciaDeDatos.ipynb
   ```
2. Ejecuta las celdas en orden:

   1. **Carga y exploraciÃ³n de datos**
   2. **Limpieza e imputaciÃ³n**
   3. **AnÃ¡lisis exploratorio (EDA)**
   4. **IngenierÃ­a de caracterÃ­sticas**
   5. **Entrenamiento de modelos**
   6. **EvaluaciÃ³n y validaciÃ³n**

## ğŸ§­ MetodologÃ­a

1. **EDA**: estadÃ­sticas descriptivas, detecciÃ³n de outliers, correlaciones.
2. **Preprocesamiento**: manejo de valores faltantes, codificaciÃ³n de variables categÃ³ricas y escalado.
3. **Modelado**: comparaciÃ³n de al menos dos algoritmos supervisados (por ejemplo, Random Forest y XGBoost).
4. **ValidaciÃ³n**: validaciÃ³n cruzada, mÃ©tricas de desempeÃ±o (RMSE, Accuracy, AUC, segÃºn el caso).
5. **InterpretaciÃ³n**: anÃ¡lisis de importancia de variables y conclusiones basadas en los resultados.

## ğŸ“¸ Capturas de pantalla

Modelo de Arbol de decision con Undersampling

<img width="700" alt="image" src="https://github.com/user-attachments/assets/d5129fd7-cb8b-450a-af28-8dda9474df22" />

El undersampling reduce aleatoriamente muestras de la clase mayoritaria para equilibrar las clases, evitando sesgos del modelo a costa de perder algo de informaciÃ³n.

Encontrar las variables mÃ¡s relevantes

<img width="848" alt="image" src="https://github.com/user-attachments/assets/8dec8f81-04df-4a78-b9f1-1a3553fab57b" />

Ordena los Ã­ndices de las caracterÃ­sticas segÃºn su importancia (de mayor a menor), imprime las columnas junto con sus valores de feature_importances_ en ese orden, y luego dibuja el Ã¡rbol de decisiÃ³n (best_clf) con los nombres de las variables y las clases etiquetadas, mostrando la estructura del modelo hasta una profundidad de 2 niveles.





## ğŸ“ˆ Resultados clave

<img width="607" alt="image" src="https://github.com/user-attachments/assets/0608e29b-820d-405a-b56b-79dad3a18ccd" />

<img width="604" alt="image" src="https://github.com/user-attachments/assets/368eba9d-58d0-448f-ba3a-d43adccf2d96" />



* El mejor modelo (Undersampling) alcanzÃ³ un **recall** de 0.7  y un **Accuracy** de 69 % en el conjunto de prueba.
* Las variables mÃ¡s relevantes fueron `var1`, `var2` y `var3`, que explican mÃ¡s del 60 % de la varianza del modelo.


**ConclusiÃ³n:** El enfoque de limpieza rigurosa, selecciÃ³n de caracterÃ­sticas y comparaciÃ³n de algoritmos permitiÃ³ desarrollar un modelo sÃ³lido, escalable y fÃ¡cil de actualizar con nuevos datos.

## ğŸ¤ Contribuciones

Â¡Las contribuciones son bienvenidas! Haz un fork, crea una rama y envÃ­a un pull request.

## ğŸ‘¤ Contacto

Pablo PÃ©rez â€“ [github.com/tu-usuario](https://github.com/tu-usuario)
Email: [tu.email@ejemplo.com](mailto:tu.email@ejemplo.com)
